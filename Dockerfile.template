FROM balenalib/jetson-nano-ubuntu:bionic

WORKDIR /usr/src/app
COPY ./deb/*.* ./

ENV DEBIAN_FRONTEND noninteractive

RUN \
    dpkg -i cuda-repo-l4t-10-0-local-10.0.326_1.0-1_arm64.deb \
    libcudnn7_7.6.3.28-1+cuda10.0_arm64.deb \
    libcudnn7-dev_7.6.3.28-1+cuda10.0_arm64.deb && \
    apt-key add /var/cuda-repo-10-0-local-10.0.326/*.pub && \
    apt-get update && \
    apt-get install cuda-compiler-10-0 cuda-samples-10-0 -y && \
    rm -rf *.deb && \
    dpkg --remove cuda-repo-l4t-10-0-local-10.0.326 && \
    dpkg -P cuda-repo-l4t-10-0-local-10.0.326 && \
    echo "/usr/lib/aarch64-linux-gnu/tegra" > /etc/ld.so.conf.d/nvidia-tegra.conf && \
    ldconfig

RUN \
    rm -rf /usr/local/cuda-10.0/targets && \
    rm -rf /usr/local/cuda-10.0/doc

# If planning to do only headles GPU computing, without video
# display do not install xorg
RUN apt-get update && apt-get install lbzip2 xorg -y && \
    tar xjf nvidia_drivers.tbz2 -C / && \
    tar xjf config.tbz2 -C / --exclude=etc/hosts --exclude=etc/hostname && \
    echo "/usr/lib/aarch64-linux-gnu/tegra" > /etc/ld.so.conf.d/nvidia-tegra.conf && ldconfig && \
    rm -rf *.tbz2

# base-image for python on any machine using a template variable,
# see more about dockerfile templates here: https://www.balena.io/docs/learn/develop/dockerfile/

# use `install_packages` if you need to install dependencies,
# for instance if you need git, just uncomment the line below.
# RUN install_packages git

RUN apt-get install -y cmake python3-dev python3-numpy python3-pip git
RUN apt-get install -y python3-scipy

RUN pip3 install -U pip setuptools
RUN pip3 install Cython dlib imutils

COPY ./build_opencv_4_1.sh ./build_opencv_4_1.sh
RUN ./build_opencv_4_1.sh

#RUN apt-get install -y libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev
#
#RUN pip3 install -U grpcio absl-py py-cpuinfo psutil portpicker six mock requests gast h5py astor termcolor protobuf keras-applications keras-preprocessing wrapt google-pasta
# TF-2.0
#RUN pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v43 tensorflow-gpu==2.0.0+nv20.1

# This will copy all files in our root to the working  directory in the container
COPY ./src ./src
#RUN wget  -O /utils/model/gender_model_weights.h5 "https://drive.google.com/file/d/1YCox_4kJ-BYeXq27uUbasu--yz28zUMV/view?usp=sharing"
#RUN wget  -O /utils/model/age_model_weights.h5 "https://drive.google.com/file/d/1wUXRVlbsni2FN9-jkS_f4UTUrm1bRLyk/view?usp=sharing"

# Enable udevd so that plugged dynamic hardware devices show up in our container.
ENV UDEV=1

# main.py will run when container starts up on the device
#CMD ["python3","-u","src/app.py"]
CMD ["sleep", "infinity"]
